{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RafuduRbqY84"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ_ujg19puCh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOoUNsJLqf_z"
      },
      "source": [
        "# Read File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cavmukITpgP",
        "outputId": "84f405e1-c3a7-47d2-bb4f-8ae35269cbdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfhhL9t03YvP"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('/content/final_books.xlsx')\n",
        "row = [2]\n",
        "df = df.get('content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uelPIUqP5y32"
      },
      "source": [
        "# install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3DGoSZZy2h_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc60b24-9ac8-404f-a1f2-51bc65748397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 61.3 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=a2321b9ddc5d8a14f6f325270e69c2ecfbb304dd4b9875bd9719316b79a54e0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154268 sha256=1e192a7eaa5d32929f5c8519d5175a632d0115a49a4ad3f5b08155ff5f6c37f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6RaAKQC59PX"
      },
      "source": [
        "# Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYZApFDT6Gk8"
      },
      "outputs": [],
      "source": [
        "import hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XK33FBy_FOQ"
      },
      "outputs": [],
      "source": [
        "informalNormalizer = hazm.InformalNormalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f5_63gvDr5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7704bb02-42e8-46f8-a7ad-bcc689b4b655"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     تی دی جیکس یک کشیش، نویسنده، سخنران آمریکایی ...\n",
              "1     کتاب حاضر که اینک در دسترس خوانندگان محترم قر...\n",
              "2     دکتر فتح الله بینا تحصیلات خود را در رشته پزش...\n",
              "3     مجموعه پیش رو مطالبیست که در گروه Evolution ت...\n",
              "4     کتاب آسمان پرستاره نوشته‌ی کتی هایدن، به زبان...\n",
              "Name: content, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "normalizer = hazm.Normalizer()\n",
        "\n",
        "df = df.apply(lambda x: normalizer.character_refinement(normalizer.affix_spacing(str(x))))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkogcZUeClZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36ebf1f-48c1-42f9-d3c1-6d3a322bca99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     تی دی جیکس یک کشیش، نویسنده، سخنران آمریکایی ...\n",
              "1     کتاب حاضر که اینک در دسترس خوانندگان محترم قر...\n",
              "2     دکتر فتح الله بینا تحصیلات خود را در رشته پزش...\n",
              "3     مجموعه پیش رو مطالبیست که در گروه Evolution ت...\n",
              "4     کتاب آسمان پرستاره نوشته‌ی کتی هایدن، به زبان...\n",
              "Name: content, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df = df.apply(lambda x: normalizer.normalize(str(x)))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dbjW0BbEMpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99fcd408-58a0-4038-b8ea-3c51d8d92348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'persian-stopwords'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 51 (delta 7), reused 5 (delta 5), pack-reused 42\u001b[K\n",
            "Unpacking objects: 100% (51/51), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kharazi/persian-stopwords.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqPzIyrXDJ1w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a24518cc-c7df-41da-a122-137fcd8400bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cb021735-6505-4118-bd6c-a90d3c5e0d31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[تی, دی, جیکس, یک, کشیش, ،, نویسنده, ،, سخنران...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[کتاب, حاضر, که, اینک, در, دسترس, خوانندگان, م...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[دکتر, فتح, الله, بینا, تحصیلات, خود, را, در, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[مجموعه, پیش, رو, مطالبیست, که, در, گروه, Evol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[کتاب, آسمان, پرستاره, نوشته‌ی, کتی, هایدن, ،,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2819</th>\n",
              "      <td>[nan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2820</th>\n",
              "      <td>[nan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2821</th>\n",
              "      <td>[کتابی, که, می‌خواهید, مطالعه, کنید, به, صورت,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2822</th>\n",
              "      <td>[nan]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2823</th>\n",
              "      <td>[nan]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2824 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb021735-6505-4118-bd6c-a90d3c5e0d31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb021735-6505-4118-bd6c-a90d3c5e0d31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb021735-6505-4118-bd6c-a90d3c5e0d31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tokens\n",
              "0     [تی, دی, جیکس, یک, کشیش, ،, نویسنده, ،, سخنران...\n",
              "1     [کتاب, حاضر, که, اینک, در, دسترس, خوانندگان, م...\n",
              "2     [دکتر, فتح, الله, بینا, تحصیلات, خود, را, در, ...\n",
              "3     [مجموعه, پیش, رو, مطالبیست, که, در, گروه, Evol...\n",
              "4     [کتاب, آسمان, پرستاره, نوشته‌ی, کتی, هایدن, ،,...\n",
              "...                                                 ...\n",
              "2819                                              [nan]\n",
              "2820                                              [nan]\n",
              "2821  [کتابی, که, می‌خواهید, مطالعه, کنید, به, صورت,...\n",
              "2822                                              [nan]\n",
              "2823                                              [nan]\n",
              "\n",
              "[2824 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "word_tokenize = hazm.word_tokenize\n",
        "token_df = pd.DataFrame()\n",
        "token_df['tokens'] =df.apply(lambda x: word_tokenize(x))\n",
        "token_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku29l7yvERHp"
      },
      "outputs": [],
      "source": [
        "chars = []\n",
        "with open('/content/persian-stopwords/chars', 'r') as f:\n",
        "    for line in f:\n",
        "      chars.append(line.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObsVkIpNFIVL"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(tokens):\n",
        "  sw = hazm.utils.stopwords_list()\n",
        "  return [item for item in tokens if item not in chars and item not in sw]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQKxUqDrFe_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d3e454-838a-4534-b878-037a2632066e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [تی, دی, جیکس, کشیش, نویسنده, سخنران, آمریکایی...\n",
              "1       [کتاب, حاضر, اینک, دسترس, خوانندگان, محترم, قر...\n",
              "2       [دکتر, فتح, الله, بینا, تحصیلات, رشته, پزشکی, ...\n",
              "3       [مجموعه, مطالبیست, گروه, Evolution, توسط, اینج...\n",
              "4       [کتاب, آسمان, پرستاره, نوشته‌ی, کتی, هایدن, زب...\n",
              "                              ...                        \n",
              "2819                                                [nan]\n",
              "2820                                                [nan]\n",
              "2821    [کتابی, می‌خواهید, مطالعه, صورت, فیلم, نامه, م...\n",
              "2822                                                [nan]\n",
              "2823                                                [nan]\n",
              "Name: without-stop-word, Length: 2824, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "token_df['without-stop-word'] = token_df['tokens'].apply(lambda x: remove_stopwords(x))\n",
        "token_df['without-stop-word']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs8sbxPToBeR"
      },
      "source": [
        "# lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mon5go2DbJ2"
      },
      "outputs": [],
      "source": [
        "def stem(tokens):\n",
        "  stemmer = hazm.Stemmer()\n",
        "  return [stemmer.stem(item) for item in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB-A2hCQhbmP"
      },
      "outputs": [],
      "source": [
        "def lem(tokens):\n",
        "  lemmatizer = hazm.Lemmatizer()\n",
        "  return [lemmatizer.lemmatize(x) for x in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mpi0VbvD7PT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447e0b4e-ff91-4a93-ad33-853491fcfc9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [ت, د, جیکس, کش, نویسنده, سخنر, آمریکا, سمینار...\n",
              "1    [کتاب, حاضر, اینک, دسترس, خوانندگ, محتر, قرار,...\n",
              "2    [دک, فتح, الله, بینا, تحصیل, رشته, پزشک, دنبال...\n",
              "3    [مجموعه, مطالبیس, گروه, Evolution, توسط, اینجا...\n",
              "4    [کتاب, آس, پرستاره, نوشته, کت, هایدن, زبان, سا...\n",
              "Name: stemmed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "token_df['stemmed'] = token_df['without-stop-word'].apply(lambda x: stem(x))\n",
        "token_df['stemmed'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL40tvx0Haop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691f99e0-2ac4-4bb4-c26d-ebae26541a62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [ت, د, جیکس, کش, نویسنده, سخنر, آمریکا, سمینار...\n",
              "1    [کتاب, حاضر, اینک, دسترس, خوانندگ, محتر, قرار,...\n",
              "2    [دک, فتح, الله, بینا, تحصیل, رشته, پزشک, دنبال...\n",
              "3    [مجموعه, مطالبیس, گروه, Evolution, توسط, اینجا...\n",
              "4    [کتاب, آس, پرستاره, نوشته, کت, هایدن, زبان, سا...\n",
              "Name: lemmetized, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "token_df['lemmetized'] = token_df['stemmed'].apply(lambda x: lem(x))\n",
        "token_df['lemmetized'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pPuFSgErVdd"
      },
      "outputs": [],
      "source": [
        "for row in token_df['without-stop-word']:\n",
        "  print(lem(row))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfzRoFK3HDWq"
      },
      "outputs": [],
      "source": [
        "token_df['lem'] = lem(item for item in token_df['without-stop-word'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inverted Index \n",
        "after lemmatization\n"
      ],
      "metadata": {
        "id": "yRRG84eWFDXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = token_df[\"lemmetized\"].tolist()\n",
        "index_map = {}\n",
        "for doc in docs:\n",
        "  doc_index = docs.index(doc) + 1\n",
        "  doc = list(set(doc))\n",
        "  for token in doc:\n",
        "    if token not in index_map.keys():\n",
        "      index_map[token] = [doc_index,]\n",
        "    else: \n",
        "      index_map[token].append(doc_index)"
      ],
      "metadata": {
        "id": "1idxhngID-Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "write output of inverted index to a csv file"
      ],
      "metadata": {
        "id": "d6SMToyAMEML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/II_lem_output.csv\", 'w', newline='') as output_file:\n",
        "  csvwriter = csv.writer(output_file)\n",
        "  for key in index_map.keys():\n",
        "    row = []\n",
        "    row.append(key)\n",
        "    for i in index_map[key]:\n",
        "      row.append(i)\n",
        "    csvwriter.writerow(row)"
      ],
      "metadata": {
        "id": "ef74sDuTLRvC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inverted Index\n",
        "after stemming"
      ],
      "metadata": {
        "id": "nKYMg7HgRuDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = token_df[\"stemmed\"].tolist()\n",
        "index_map = {}\n",
        "for doc in docs:\n",
        "  doc_index = docs.index(doc) + 1\n",
        "  doc = list(set(doc))\n",
        "  for token in doc:\n",
        "    if token not in index_map.keys():\n",
        "      index_map[token] = [doc_index,]\n",
        "    else: \n",
        "      index_map[token].append(doc_index)"
      ],
      "metadata": {
        "id": "cdVz2gl0R1E1"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "write output of inverted index to a csv file"
      ],
      "metadata": {
        "id": "DqSD96DFR8zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/II_stm_output.csv\", 'w', newline='') as output_file:\n",
        "  csvwriter = csv.writer(output_file)\n",
        "  for key in index_map.keys():\n",
        "    row = []\n",
        "    row.append(key)\n",
        "    for i in index_map[key]:\n",
        "      row.append(i)\n",
        "    csvwriter.writerow(row)"
      ],
      "metadata": {
        "id": "dlbj9dWnSBue"
      },
      "execution_count": 49,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "IR-HW1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}